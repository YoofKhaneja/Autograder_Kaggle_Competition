{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-11-21T17:17:09.658678Z",
     "iopub.status.busy": "2022-11-21T17:17:09.658114Z",
     "iopub.status.idle": "2022-11-21T17:17:13.981422Z",
     "shell.execute_reply": "2022-11-21T17:17:13.980302Z"
    },
    "papermill": {
     "duration": 4.331573,
     "end_time": "2022-11-21T17:17:13.984084",
     "exception": false,
     "start_time": "2022-11-21T17:17:09.652511",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/madlad/miniconda3/envs/Data_Mining_Project/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import wandb\n",
    "import torch\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "from transformers import AutoTokenizer,AutoModel,AutoConfig\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-21T17:17:13.991871Z",
     "iopub.status.busy": "2022-11-21T17:17:13.991272Z",
     "iopub.status.idle": "2022-11-21T17:17:14.009384Z",
     "shell.execute_reply": "2022-11-21T17:17:14.008536Z"
    },
    "papermill": {
     "duration": 0.024163,
     "end_time": "2022-11-21T17:17:14.011380",
     "exception": false,
     "start_time": "2022-11-21T17:17:13.987217",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class EssayModel(pl.LightningModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.dev = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        self.flag = 0\n",
    "        self.loss_fn = nn.MSELoss()\n",
    "        self.bert = AutoModel.from_pretrained(\"Models/bert_model_offline/\")\n",
    "        \n",
    "        for param in self.bert.parameters():\n",
    "            param.requires_grad=False\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(\"Models/bert_tokenizer_offline/\")\n",
    "        #self.tokenizer = AutoTokenizer.from_config(AutoConfig.from_pretrained(\"bert-base-uncased\"))\n",
    "        self.pool = nn.AvgPool1d(5,2)\n",
    "        self.l1 = nn.Linear(768,500)\n",
    "        self.l2 =  nn.Linear(500,200)\n",
    "        self.l3 = nn.Linear(200,6)\n",
    "        self.init_weights(self.l3)\n",
    "    \n",
    "    def init_weights(self,module):\n",
    "        if isinstance(module,nn.Linear):\n",
    "            #nn.init.normal(module.weight,3.5,1.5)\n",
    "            module.bias.data.fill_(3.5)\n",
    "            print(\"Weight initialized\")\n",
    "        \n",
    "    def forward(self,inputs):\n",
    "        x = self.bert(**inputs)\n",
    "        hidden_states = x[0]\n",
    "        attention_mask = inputs[\"attention_mask\"]\n",
    "        mask = attention_mask.unsqueeze(-1).expand(hidden_states.size()).float()\n",
    "        #print(\"M: \",mask.shape)\n",
    "        temp = torch.sum(hidden_states*mask,1)\n",
    "        #temp = torch.flatten(hidden_states,start_dim=1)\n",
    "        #print(\"T: \",temp.shape)\n",
    "        #pooled_output = pooled_output[:, 0, :]\n",
    "        \n",
    "        x = F.relu(self.l1(temp))\n",
    "        #print(x.shape)\n",
    "        x = F.relu(self.l2(x))\n",
    "        out = self.l3(x)\n",
    "        return out\n",
    "    \n",
    "    def training_step(self,batch,batch_idx):\n",
    "        X,y = batch\n",
    "        \n",
    "        X_tokens = self.tokenizer(list(X),padding=True,truncation=True,return_tensors=\"pt\")\n",
    "        X_tokens.to(self.dev)\n",
    "        y.to(self.dev)\n",
    "        out = self(X_tokens)\n",
    "        loss = self.loss_fn(out,y)\n",
    "        \n",
    "        if self.flag==0:\n",
    "            #print(\"Out: \",out)\n",
    "            #print(\"Y: \",y)\n",
    "            self.flag=1\n",
    "            \n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self,batch,batch_idx):\n",
    "        X,y = batch\n",
    "        \n",
    "        X_tokens = self.tokenizer(list(X),padding=True,truncation=True,return_tensors=\"pt\")\n",
    "        X_tokens.to(self.dev)\n",
    "        out = self(X_tokens)\n",
    "        \n",
    "        loss = self.loss_fn(out,y)\n",
    "        \n",
    "        out = out.detach().cpu().numpy()\n",
    "        y = y.detach().cpu().numpy()\n",
    "        \n",
    "        metric = MCRMSE(out,y)\n",
    "        \n",
    "        return {\"metric\":metric,\"loss\":loss}\n",
    "    \n",
    "    \n",
    "    \n",
    "    def training_epoch_end(self,outputs):\n",
    "        mean_loss = np.mean(np.array([t['loss'].detach().cpu().numpy() for t in outputs]))\n",
    "        self.log(\"Train epoch loss: \",mean_loss)\n",
    "        self.flag=0\n",
    "        \n",
    "        \n",
    "        \n",
    "    def validation_epoch_end(self,outputs):\n",
    "        \n",
    "        mean_metric = np.mean(np.array([t[\"metric\"] for t in outputs]))\n",
    "        mean_loss = np.mean(np.array([t[\"loss\"].detach().cpu().numpy() for t in outputs]))\n",
    "        self.log(\"Val MCRMSE: \",mean_metric)\n",
    "        self.log(\"Val epoch loss: \",mean_loss)\n",
    "        \n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(),lr=0.001)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-21T17:17:14.018461Z",
     "iopub.status.busy": "2022-11-21T17:17:14.017930Z",
     "iopub.status.idle": "2022-11-21T17:17:22.291164Z",
     "shell.execute_reply": "2022-11-21T17:17:22.290090Z"
    },
    "papermill": {
     "duration": 8.279191,
     "end_time": "2022-11-21T17:17:22.293284",
     "exception": false,
     "start_time": "2022-11-21T17:17:14.014093",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weight initialized\n",
      "Weight initialized\n"
     ]
    }
   ],
   "source": [
    "essay_model = EssayModel()\n",
    "model = essay_model.load_from_checkpoint(\"Models/bert_model.ckpt\")\n",
    "model = model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-21T17:17:22.301404Z",
     "iopub.status.busy": "2022-11-21T17:17:22.300472Z",
     "iopub.status.idle": "2022-11-21T17:17:22.329462Z",
     "shell.execute_reply": "2022-11-21T17:17:22.328314Z"
    },
    "papermill": {
     "duration": 0.03501,
     "end_time": "2022-11-21T17:17:22.331489",
     "exception": false,
     "start_time": "2022-11-21T17:17:22.296479",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_id</th>\n",
       "      <th>full_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000C359D63E</td>\n",
       "      <td>when a person has no experience on a job their...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000BAD50D026</td>\n",
       "      <td>Do you think students would benefit from being...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00367BB2546B</td>\n",
       "      <td>Thomas Jefferson once states that \"it is wonde...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        text_id                                          full_text\n",
       "0  0000C359D63E  when a person has no experience on a job their...\n",
       "1  000BAD50D026  Do you think students would benefit from being...\n",
       "2  00367BB2546B  Thomas Jefferson once states that \"it is wonde..."
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = pd.read_csv(\"../../data/test.csv\")\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-21T17:17:22.338570Z",
     "iopub.status.busy": "2022-11-21T17:17:22.338280Z",
     "iopub.status.idle": "2022-11-21T17:17:22.343778Z",
     "shell.execute_reply": "2022-11-21T17:17:22.343001Z"
    },
    "papermill": {
     "duration": 0.010944,
     "end_time": "2022-11-21T17:17:22.345580",
     "exception": false,
     "start_time": "2022-11-21T17:17:22.334636",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class EssayDatasetTest(Dataset):\n",
    "    def __init__(self,df):\n",
    "        self.essays = df.full_text.values\n",
    "        self.ids = df.text_id.values\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.essays)\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        essay = self.essays[idx]\n",
    "        id = self.ids[idx]\n",
    "        return id,essay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-21T17:17:22.353016Z",
     "iopub.status.busy": "2022-11-21T17:17:22.352226Z",
     "iopub.status.idle": "2022-11-21T17:17:22.360327Z",
     "shell.execute_reply": "2022-11-21T17:17:22.359610Z"
    },
    "papermill": {
     "duration": 0.013445,
     "end_time": "2022-11-21T17:17:22.362001",
     "exception": false,
     "start_time": "2022-11-21T17:17:22.348556",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_dataset = EssayDatasetTest(test_data)\n",
    "test_dataloader = DataLoader(test_dataset,batch_size=1,shuffle=False,num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-21T17:17:22.369514Z",
     "iopub.status.busy": "2022-11-21T17:17:22.368866Z",
     "iopub.status.idle": "2022-11-21T17:17:25.026171Z",
     "shell.execute_reply": "2022-11-21T17:17:25.024967Z"
    },
    "papermill": {
     "duration": 2.663603,
     "end_time": "2022-11-21T17:17:25.028777",
     "exception": false,
     "start_time": "2022-11-21T17:17:22.365174",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 3/3 [00:00<00:00,  3.03it/s]\n"
     ]
    }
   ],
   "source": [
    "import tqdm\n",
    "test_texts = test_data.full_text\n",
    "preds = []\n",
    "id_list = []\n",
    "for ids,text in tqdm.tqdm(test_dataloader):\n",
    "    X_tokens = model.tokenizer(list(text),padding=True,truncation=True,return_tensors=\"pt\")\n",
    "    with torch.no_grad():\n",
    "        op = model.forward(X_tokens)\n",
    "    preds.extend(op.detach().numpy())\n",
    "    id_list.extend(ids)\n",
    "\n",
    "preds = np.array(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-21T17:17:25.037718Z",
     "iopub.status.busy": "2022-11-21T17:17:25.037387Z",
     "iopub.status.idle": "2022-11-21T17:17:25.066750Z",
     "shell.execute_reply": "2022-11-21T17:17:25.065859Z"
    },
    "papermill": {
     "duration": 0.036468,
     "end_time": "2022-11-21T17:17:25.068953",
     "exception": false,
     "start_time": "2022-11-21T17:17:25.032485",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_id</th>\n",
       "      <th>cohesion</th>\n",
       "      <th>syntax</th>\n",
       "      <th>vocabulary</th>\n",
       "      <th>phraseology</th>\n",
       "      <th>grammar</th>\n",
       "      <th>conventions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000C359D63E</td>\n",
       "      <td>2.932586</td>\n",
       "      <td>2.771767</td>\n",
       "      <td>3.098914</td>\n",
       "      <td>2.928413</td>\n",
       "      <td>2.792662</td>\n",
       "      <td>2.617472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000BAD50D026</td>\n",
       "      <td>2.907489</td>\n",
       "      <td>2.654220</td>\n",
       "      <td>2.890331</td>\n",
       "      <td>2.460315</td>\n",
       "      <td>2.534201</td>\n",
       "      <td>2.942874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00367BB2546B</td>\n",
       "      <td>3.563079</td>\n",
       "      <td>3.487792</td>\n",
       "      <td>3.653115</td>\n",
       "      <td>3.539544</td>\n",
       "      <td>3.470293</td>\n",
       "      <td>3.496453</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        text_id  cohesion    syntax  vocabulary  phraseology   grammar  \\\n",
       "0  0000C359D63E  2.932586  2.771767    3.098914     2.928413  2.792662   \n",
       "1  000BAD50D026  2.907489  2.654220    2.890331     2.460315  2.534201   \n",
       "2  00367BB2546B  3.563079  3.487792    3.653115     3.539544  3.470293   \n",
       "\n",
       "   conventions  \n",
       "0     2.617472  \n",
       "1     2.942874  \n",
       "2     3.496453  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LABEL_COLUMNS = [\"cohesion\",\"syntax\",\"vocabulary\",\"phraseology\",\"grammar\",\"conventions\"]\n",
    "submission = pd.DataFrame()\n",
    "submission[\"text_id\"] = test_data.text_id\n",
    "submission.loc[:,LABEL_COLUMNS] = preds\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-21T17:17:25.077585Z",
     "iopub.status.busy": "2022-11-21T17:17:25.077233Z",
     "iopub.status.idle": "2022-11-21T17:17:25.084461Z",
     "shell.execute_reply": "2022-11-21T17:17:25.083654Z"
    },
    "papermill": {
     "duration": 0.013582,
     "end_time": "2022-11-21T17:17:25.086426",
     "exception": false,
     "start_time": "2022-11-21T17:17:25.072844",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "submission.to_csv(\"submission.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.003488,
     "end_time": "2022-11-21T17:17:25.093779",
     "exception": false,
     "start_time": "2022-11-21T17:17:25.090291",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python Essay_Project",
   "language": "python",
   "name": "data_mining_project"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 24.109494,
   "end_time": "2022-11-21T17:17:26.218571",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-11-21T17:17:02.109077",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
